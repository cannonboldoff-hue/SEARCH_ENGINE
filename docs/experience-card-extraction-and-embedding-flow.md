# Experience Card Extraction and Embedding Flow (V2)

This document describes the **current** end-to-end pipeline for converting messy user text into **experience cards** (parent + child), storing **rich structured data**, and generating **embeddings for both parents and children**.

The design goals are:

- **Simple pipeline:** 3 steps (cleanup → extraction → validation)
- **No atomization:** avoid context loss across companies/projects/time/location
- **Rich storage:** keep **all extracted fields** (not just title/summary/tags)
- **Search-ready:** store structured filters (dates, city/country, ongoing) + search phrases + embeddings
- **Traceability:** keep both `raw_text_original` and `raw_text_cleaned`

---

## Overview

### High-level flow

1. **User Input** → Raw text entered in the Builder UI
2. **Cleanup** → Lightweight cleanup / normalization (no new facts)
3. **Extraction (one pass)** → Extract **all** parent + child cards from the full text
4. **Validation (one pass)** → Validate schema, remove hallucinations, dedupe, enforce consistency
5. **Persistence** → Store draft set + cards (parents + children) with rich JSON + filter columns
6. **Review** → Frontend displays cards; user edits/selects
7. **Commit / Approve** → Approve selected cards
8. **Embedding** → Build searchable documents and embed **parents + children**
9. **Storage** → Update approved cards with embeddings

---

## Data model (storage contract)

### Table: `raw_experiences`

Stores the raw input **and** the cleaned version.

| Column | Type | Constraints | Description |
|---|---|---|---|
| `id` | UUID | PK | **raw_experience_id** (represents a **raw text version**) |
| `person_id` | UUID | FK → `people.id` | Owner |
| `raw_text_original` | TEXT | NOT NULL | Verbatim user input |
| `raw_text_cleaned` | TEXT | NULLABLE | Output of Step 1 (cleanup). Nullable until cleanup runs |
| `created_at` | TIMESTAMP TZ | default now() | Timestamp |

> **Definition:** `raw_experience_id = raw text version`.  
Any time the user submits a new raw text payload, a new `raw_experiences` row is created.

---

### Table: `draft_sets`

Represents an **extraction run** over a specific raw text version.

| Column | Type | Constraints | Description |
|---|---|---|---|
| `id` | UUID | PK | **draft_set_id** (represents an **extraction run**) |
| `person_id` | UUID | FK → `people.id` | Owner |
| `raw_experience_id` | UUID | FK → `raw_experiences.id` | Raw text version used for this run |
| `run_version` | INT | NOT NULL | Incrementing run number per raw text version |
| `metadata` | JSONB | NULLABLE | Optional run metadata |
| `created_at` | TIMESTAMP TZ | default now() | Timestamp |

> **Definition:** `draft_set_id = extraction run`.  
Multiple draft sets can exist for the same `raw_experience_id` (e.g., re-run extraction with improved prompts).

---

### Tables: `experience_cards` and `experience_card_children`

Both parents and children store:

- **Display fields**: title/context/tags/etc.
- **Filter fields**: start/end/ongoing + city/country + time_text
- **Rich fields**: stored in JSON (parents: `card_json`, children: existing JSON columns)
- **Search phrases**: persisted for lexical fallback and explainability
- **Embeddings**: stored for **both** parents and children

#### Shared columns (parents + children)

| Column | Type | Description |
|---|---|---|
| `id` | UUID | Card id |
| `person_id` | UUID | Owner |
| `raw_experience_id` | UUID | Source raw experience |
| `draft_set_id` | UUID | Extraction run that created this draft |
| `status` | VARCHAR | `DRAFT` / `APPROVED` / `HIDDEN` |
| `human_edited` | BOOLEAN | Manual edits applied |
| `locked` | BOOLEAN | Locked from editing |
| `raw_text` | TEXT | Supporting excerpt for this card |
| `title` | VARCHAR | Headline |
| `context` | TEXT | Summary |
| `tags` | ARRAY(VARCHAR) | Normalized topic tags |
| `company` | VARCHAR | Company/org (if present) |
| `role_title` | VARCHAR | Role label (if present) |
| `time_text` | VARCHAR | Free-text time span (e.g., `"2 years"`, `"2021–2023"`) |
| `start_date` | DATE | Nullable |
| `end_date` | DATE | Nullable |
| `is_ongoing` | BOOLEAN | Nullable |
| `city` | VARCHAR | Nullable |
| `country` | VARCHAR | Nullable |
| `search_phrases` | ARRAY(TEXT) | 5–15 phrases generated by validator |
| `search_phrases` | ARRAY(TEXT) | 5–15 phrases generated by validator |
| `embedding` | VECTOR(384) | Normalized embedding vector |

#### Parent-only columns (`experience_cards`)

| Column | Type | Description |
|---|---|---|
| `team` | VARCHAR | Optional |
| `card_json` | JSONB | Full validated card object (canonical source-of-truth) |
| *(other parent-specific app fields)* | | |

#### Child-only columns (`experience_card_children`)

| Column | Type | Description |
|---|---|---|
| `parent_id` | UUID | FK → `experience_cards.id` |
| `depth` | INT | Always 1 |
| `relation_type` | VARCHAR | Child relationship enum |
| `tooling` | JSONB | Rich tooling object (child only) |
| `entities` | JSONB | Rich entities array (child only) |
| `actions` | JSONB | Rich actions array (child only) |
| `outcomes` | JSONB | Rich outcomes array (child only) |
| `topics` | JSONB | Rich topics array (child only) |
| `evidence` | JSONB | Rich evidence array (child only) |

---

## Pipeline (3 steps)

### Step 0: API entry point

**Location:** `apps/api/src/routers/builder.py` (example)

- Endpoint receives `{ raw_text: string }`
- Creates `raw_experiences` row (stores `raw_text_original`)
- Creates `draft_sets` row (new `draft_set_id`) pointing to the raw experience version
- Runs the 3-step pipeline and persists draft cards

---

## Step 1: Cleanup

**Input:** `raw_text_original`  
**Output:** `raw_text_cleaned` (stored on `raw_experiences`)

**Goal:** Clean up formatting and obvious noise **without changing meaning**.

Recommended cleanup rules (non-LLM preferred):
- Trim whitespace, collapse multiple spaces/newlines
- Normalize bullets, remove duplicate empty lines
- Preserve all numbers, names, proper nouns as-is

Optional (LLM-lite) cleanup:
- Fix obvious grammar/typos
- Expand abbreviations **only if unambiguous**
- Do **not** add new facts, do **not** infer dates/companies

---

## Step 2: Extraction (one pass)

**Key change:** Extraction is performed on the **full cleaned text in one call**, so the model can correctly attach:
- achievements to the right company/role/time/location
- multiple projects under the right parent
- child evidence/tools/outcomes under the right parent

### Output shape (recommended)

The extractor returns a JSON object:

```json
{
  "parents": [
    {
      "parent": {
        "headline": "...",
        "summary": "...",
        "raw_text": "...",
        "intent": "work|project|achievement|education|other",
        "roles": [...],
        "time": {"start": "...", "end": "...", "ongoing": true, "text": "...", "confidence": "..."},
        "location": {"city": "...", "country": "...", "text": "...", "confidence": "..."},
        "topics": [...],
        "actions": [...],
        "entities": [...],
        "tooling": {...},
        "outcomes": [...],
        "evidence": [...],
        "privacy": {...},
        "quality": {...},
        "index": {"search_phrases": ["..."]}
      },
      "children": [
        {
          "relation_type": "tool_used|method_used|outcome_detail|...",
          "headline": "...",
          "summary": "...",
          "raw_text": "...",
          "intent": "skill_application|method_used|artifact_created|outcome|...",
          "time": {...},
          "location": {...},
          "topics": [...],
          "actions": [...],
          "entities": [...],
          "tooling": {...},
          "outcomes": [...],
          "evidence": [...],
          "privacy": {...},
          "quality": {...},
          "index": {"search_phrases": ["..."]}
        }
      ]
    }
  ]
}
```

Notes:
- One parent represents one dominant intent block.
- Multi-company/multi-project text should produce multiple parents.
- `raw_text` is a best-effort supporting excerpt (offsets optional).

---

## Step 3: Validation (one pass)

Validator input: the whole extracted object (`parents[]` with nested `children[]`) plus:
- `raw_text_original`
- `raw_text_cleaned`

Validator responsibilities:
- Enforce schema requirements (required fields present)
- Remove hallucinations (anything not supported by raw text)
- Normalize labels (roles/topics/tools) without changing facts
- Deduplicate overlapping cards (merge or drop near-duplicates)
- Ensure child cards reference valid parents
- Ensure time/location fields follow rules (no guessed dates/locations)
- Generate **search_phrases (5–15) per card**
- Set `quality.overall_confidence` and `needs_clarification` flags

---

## Persistence (Draft)

### What gets stored for drafts

For **every parent and every child**:
- Store typed columns for display + filtering:
  - `raw_text`, `title`, `context`, `tags`, `company`, `role_title`
  - `time_text`, `start_date`, `end_date`, `is_ongoing`
  - `city`, `country`
- Store `search_phrases` for lexical search and explainability
- Store canonical `card_json` on parents (full validated object)
- Store `draft_set_id` on all cards
For **children**, also store rich JSON in typed columns:
  - `tooling`, `entities`, `actions`, `outcomes`, `topics`, `evidence`

Embeddings remain `NULL` while status is `DRAFT`.

---

## Frontend review

Frontend receives `draft_set_id` + full card family, displays:
- Parent cards with nested children
- Search phrases (optional UI)
- Confidence + clarification question (optional UI)

User can:
- Edit card title/context/tags and key structured fields
- Delete irrelevant cards
- Commit/approve selected cards

---

## Approval + Embedding (Parents **and** Children)

### Step A: Commit endpoint

`POST /draft-sets/{draft_set_id}/commit`

Backend loads selected cards by `draft_set_id` and approves them.  
**Important:** Approval now embeds:
- all selected parent cards
- all selected child cards

### Step B: Build searchable document for embedding

Embeddings should represent **everything that is present** on the card.

Recommended `search_document` builder:

- Base:
  - title, context
  - company, role_title
  - time_text + normalized dates
  - city, country
  - tags
  - search_phrases
- Rich fields (flattened):
  - tooling.tools, tooling.processes
  - entities.name (+ type)
  - actions.verb
  - outcomes.label + value_text + metric
  - topics.label/raw (if present)
- Child-only:
  - relation_type
  - add parent title/company/time/location to strengthen retrieval context

Example (conceptual):

```python
def card_search_document(card, parent=None) -> str:
    parts = [
        card.title, card.context,
        card.company, card.role_title,
        card.time_text,
        _date_range(card.start_date, card.end_date, card.is_ongoing),
        card.city, card.country,
        " ".join(card.tags or []),
        " ".join(card.search_phrases or []),
        _flatten_tooling(card.tooling),
        _flatten_entities(card.entities),
        _flatten_actions(card.actions),
        _flatten_outcomes(card.outcomes),
        _flatten_topics(card.topics_json),
    ]
    if card.is_child:
        parts.append(card.relation_type or "")
        if parent:
            parts.extend([parent.title, parent.company, parent.time_text, parent.city, parent.country])
    return " ".join([p for p in parts if p])
```

### Step C: Generate embeddings and store

- Call embedding provider with `search_document` for each approved card
- L2 normalize vectors
- Store into:
  - `experience_cards.embedding` for parents
  - `experience_card_children.embedding` for children
- Set `status = APPROVED` for all committed cards

---

## Why this fixes the earlier issues

- **No atomization breakage:** extraction is done once on the whole text → better company/time binding.
- **Rich data is stored for parents too:** not just children.
- **Search phrases are persisted:** useful for lexical fallback and explainability.
- **Children are embedded:** child details become directly retrievable.
- **Filters become reliable:** structured `start_date/end_date/is_ongoing/city/country` enable exact constraints.

---

## Quick checklist (implementation)

- [ ] Add `raw_text_cleaned` to `raw_experiences`
- [ ] Add `draft_sets` table and store `draft_set_id` on cards
- [ ] Add structured columns to both parent and child tables:
      `start_date, end_date, is_ongoing, city, country, time_text`
- [ ] Add `search_phrases` column to both parent and child tables
- [ ] Add `card_json` for parents and children; keep child rich JSON columns
- [ ] Replace pipeline with 3 steps: cleanup → extract-all → validate-all
- [ ] Update commit/approve flow to embed **parents + children**
- [ ] Update searchable document builder to include rich fields + search_phrases

