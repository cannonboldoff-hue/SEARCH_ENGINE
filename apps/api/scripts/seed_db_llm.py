"""
Seed the database using an LLM to generate unique, non-templated users and experiences.
Each person and experience is generated by the model so no two are alike.

Requires: OPENAI_API_KEY or CHAT_API_BASE_URL (and optionally CHAT_API_KEY, CHAT_MODEL) in .env.
Run from apps/api: python scripts/seed_db_llm.py [--users N] [--cards-min M] [--cards-max K] [--delay D] [--temperature T]
"""
import argparse
import asyncio
import json
import logging
import re
import sys
from datetime import date, datetime
from pathlib import Path

# Ensure src is importable when run from repo root or apps/api
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

logger = logging.getLogger(__name__)

from sqlalchemy import select
from src.core import hash_password
from src.db.session import async_session
from src.db.models import (
    Person,
    Bio,
    VisibilitySettings,
    ContactDetails,
    CreditWallet,
    CreditLedger,
    ExperienceCard,
    ExperienceCardChild,
)
from src.domain import ALLOWED_CHILD_TYPES
from src.providers import get_chat_provider, ChatServiceError, ChatRateLimitError

SEED_PASSWORD = "SeedPassword123!"
SIGNUP_CREDITS = 1000
DEFAULT_USERS = 10
DEFAULT_CARDS_MIN = 3
DEFAULT_CARDS_MAX = 6
DEFAULT_DELAY_SEC = 3.0  # Between batches and users; increase (e.g. 5) if you hit 429 rate limits

CHILD_TYPES_STR = ", ".join(ALLOWED_CHILD_TYPES)
INTENTS_STR = "work, education, project, business, research, achievement, learning, other"
SENIORITY_STR = "entry, mid, senior, lead, executive"
EMPLOYMENT_STR = "full_time, part_time, contract, internship, freelance"

# Max experiences per single LLM call to keep JSON small and parseable
MAX_EXPERIENCES_PER_CALL = 8


def _repair_json_simple(text: str) -> str:
    """Apply simple fixes for LLM-generated JSON."""
    # Remove trailing commas before } or ]
    text = re.sub(r",(\s*})", r"\1", text)
    text = re.sub(r",(\s*])", r"\1", text)
    return text


def _parse_json_from_llm(text: str) -> dict:
    """Extract JSON from LLM output (may be wrapped in ```json ... ```). Tries repair + json_repair on failure."""
    text = text.strip()
    # Remove markdown code block if present
    if "```" in text:
        match = re.search(r"```(?:json)?\s*([\s\S]*?)```", text)
        if match:
            text = match.group(1).strip()
    # Find first { and last }
    start = text.find("{")
    end = text.rfind("}")
    if start != -1 and end != -1 and end > start:
        text = text[start : end + 1]

    # 1) Try standard parse
    last_error = None
    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        last_error = e

    # 2) Simple repair (trailing commas) then parse
    try:
        repaired = _repair_json_simple(text)
        return json.loads(repaired)
    except json.JSONDecodeError:
        pass

    # 3) Use json_repair for LLM-style output (single quotes, unquoted keys, etc.)
    try:
        import json_repair
        return json_repair.loads(text)
    except Exception:
        pass

    raise last_error if last_error else json.JSONDecodeError("Invalid JSON", text, 0)


def _parse_date(s: str | None) -> date | None:
    if not s or not isinstance(s, str):
        return None
    s = s.strip()[:10]
    for fmt in ("%Y-%m-%d", "%Y-%m", "%Y"):
        try:
            d = datetime.strptime(s, fmt).date()
            return d
        except ValueError:
            continue
    return None


def _build_prompt(user_index: int, num_experiences: int, background: str) -> str:
    return f"""You are generating a single unique person and their work/education experiences for a seed database. Be creative and varied. Do NOT use any template or repeated phrasing. This is person number {user_index}; make them completely different from anyone else.

Background for this person (pick one and stick to it for all experiences): {background}

Generate exactly one person and {num_experiences} experiences. For each experience:
1. raw_text: Write a long, messy, realistic paragraph (150-400 words) as if the person pasted it from their notes or memory. Use informal language, run-on sentences, tangents, specific details (tools, projects, team size, one-off events), and varied sentence structure. No bullet points. Do not summarize.
2. title: Short headline for the role (e.g. "Senior Engineer at Acme").
3. normalized_role: The job title only.
4. company_name, domain, sub_domain (optional), company_type (e.g. startup, enterprise, nonprofit).
5. start_date, end_date: ISO dates YYYY-MM-DD (or YYYY-MM if exact day unknown).
6. is_current: boolean.
7. location: city/region/country string.
8. employment_type: one of {EMPLOYMENT_STR}.
9. summary: 1-2 sentence clean summary.
10. intent_primary: one of {INTENTS_STR}.
11. seniority_level: one of {SENIORITY_STR}.
12. children: Array of 4-6 child cards. Each child has a DIFFERENT child_type from this exact list: {CHILD_TYPES_STR}. Each child has: child_type, label (short descriptive string), value (JSON object with rich details as below). Use DIFFERENT child_type for each child; include varied types (e.g. skills, tools, metrics, achievements, responsibilities, collaborations, certifications).
   - skills: value must include description (what skill), level (e.g. expert, advanced, intermediate).
   - tools: value must include name, description (how used), optionally category.
   - metrics: value must include metric (e.g. "revenue growth"), value or result (number or string), context.
   - achievements: value must include description, result or impact, optionally timeframe.
   - responsibilities: value must include description, scope (e.g. team size, area).
   - collaborations: value must include who (team/role), what (description), outcome.
   - domain_knowledge: value must include domain, description, depth (e.g. deep, broad).
   - exposure: value must include area, description, level.
   - education: value must include institution, degree_or_program, focus, dates if relevant.
   - certifications: value must include name, issuer, year, optionally credential_id.

Output valid JSON only, no markdown or explanation. Use this exact structure (dates as strings, value as object with the keys above as relevant):

{{
  "first_name": "string",
  "last_name": "string",
  "display_name": "string",
  "experiences": [
    {{
      "raw_text": "long messy paragraph...",
      "title": "string",
      "normalized_role": "string",
      "company_name": "string",
      "domain": "string",
      "sub_domain": "string or null",
      "company_type": "string",
      "start_date": "YYYY-MM-DD",
      "end_date": "YYYY-MM-DD",
      "is_current": false,
      "location": "string",
      "employment_type": "string",
      "summary": "string",
      "intent_primary": "string",
      "seniority_level": "string",
      "children": [
        {{ "child_type": "skills", "label": "e.g. Python & data pipelines", "value": {{ "description": "Built ETL pipelines and APIs", "level": "advanced" }} }},
        {{ "child_type": "tools", "label": "e.g. AWS, Snowflake", "value": {{ "name": "Snowflake", "description": "Warehouse and analytics", "category": "data" }} }},
        {{ "child_type": "metrics", "label": "e.g. Performance impact", "value": {{ "metric": "Query latency", "value": "40% reduction", "context": "Production dashboards" }} }},
        {{ "child_type": "achievements", "label": "e.g. Launch award", "value": {{ "description": "Shipped product X", "result": "Won internal award", "timeframe": "2023" }} }},
        {{ "child_type": "responsibilities", "label": "e.g. Backend ownership", "value": {{ "description": "Owned payment services", "scope": "Team of 4, cross-region" }} }},
        {{ "child_type": "certifications", "label": "e.g. AWS Certified", "value": {{ "name": "AWS Solutions Architect", "issuer": "Amazon", "year": "2022" }} }}
      ]
    }}
  ]
}}"""


def _build_prompt_more_experiences(
    first_name: str, last_name: str, background: str, num_experiences: int
) -> str:
    """Prompt for an additional batch of experiences for the same person (no person fields)."""
    return f"""Generate {num_experiences} more work/education experiences for this person. Same background: {background}. Person: {first_name} {last_name}. Be creative and varied; do NOT repeat the same companies or roles. Each experience must have:

1. raw_text: Long messy paragraph (80-200 words), informal, specific details. No bullet points.
2. title, normalized_role, company_name, domain, sub_domain (optional), company_type, start_date (YYYY-MM-DD), end_date, is_current, location, employment_type (one of {EMPLOYMENT_STR}), summary, intent_primary (one of {INTENTS_STR}), seniority_level (one of {SENIORITY_STR}).
3. children: 4-6 items, each with a DIFFERENT child_type from: {CHILD_TYPES_STR}. Each child: child_type, label, value (object with rich details: for skills use description+level; tools use name+description; metrics use metric+value+context; achievements use description+result; responsibilities use description+scope; collaborations use who+what+outcome; certifications use name+issuer+year; etc.).

Output valid JSON only:
{{ "experiences": [ {{ "raw_text": "...", "title": "...", "normalized_role": "...", "company_name": "...", "domain": "...", "sub_domain": null, "company_type": "...", "start_date": "YYYY-MM-DD", "end_date": "YYYY-MM-DD", "is_current": false, "location": "...", "employment_type": "...", "summary": "...", "intent_primary": "...", "seniority_level": "...", "children": [ {{ "child_type": "skills", "label": "...", "value": {{ "description": "...", "level": "..." }} }}, {{ "child_type": "tools", "label": "...", "value": {{ "name": "...", "description": "..." }} }}, ... (4-6 children with different types and detailed value objects) ] }} ] }}"""


async def generate_one_person(
    provider, user_index: int, num_experiences: int, background: str, temperature: float = 0.85
) -> dict:
    """Call LLM to generate one person with experiences. Returns parsed JSON. num_experiences capped at MAX_EXPERIENCES_PER_CALL."""
    num_experiences = min(num_experiences, MAX_EXPERIENCES_PER_CALL)
    prompt = _build_prompt(user_index, num_experiences, background)
    response = await provider.chat(prompt, max_tokens=16000, temperature=temperature)
    return _parse_json_from_llm(response)


async def generate_more_experiences(
    provider,
    first_name: str,
    last_name: str,
    background: str,
    num_experiences: int,
    temperature: float = 0.85,
) -> dict:
    """Call LLM to generate another batch of experiences only. Returns {"experiences": [...]}."""
    num_experiences = min(num_experiences, MAX_EXPERIENCES_PER_CALL)
    prompt = _build_prompt_more_experiences(first_name, last_name, background, num_experiences)
    response = await provider.chat(prompt, max_tokens=12000, temperature=temperature)
    data = _parse_json_from_llm(response)
    if "experiences" not in data:
        data = {"experiences": []}
    return data


def normalize_child_value(value) -> dict:
    """Ensure value is a dict for JSONB."""
    if isinstance(value, dict):
        return value
    if isinstance(value, (list, str, int, float, bool)):
        return {"value": value}
    return {"value": str(value)}


async def seed_with_llm(
    num_users: int,
    cards_min: int,
    cards_max: int,
    delay_sec: float,
    temperature: float = 0.85,
):
    import random
    backgrounds = ["tech", "non_tech", "business"]
    hashed = hash_password(SEED_PASSWORD)
    provider = get_chat_provider()

    async with async_session() as session:
        for i in range(num_users):
            background = random.choice(backgrounds)
            num_cards = random.randint(cards_min, cards_max)
            email = f"seed.llm.user{i+1}.{background}@example.com"
            num_batches = (num_cards + MAX_EXPERIENCES_PER_CALL - 1) // MAX_EXPERIENCES_PER_CALL
            logger.info("User %s/%s: generating %s experiences (%s LLM batch/batches)", i + 1, num_users, num_cards, num_batches)

            # Batch LLM calls: at most MAX_EXPERIENCES_PER_CALL per call to keep JSON parseable
            experiences = []
            first, last, display_name = None, None, None

            try:
                offset = 0
                while offset < num_cards:
                    batch_size = min(MAX_EXPERIENCES_PER_CALL, num_cards - offset)
                    if offset == 0:
                        data = await generate_one_person(
                            provider, i + 1, batch_size, background, temperature
                        )
                        first = (data.get("first_name") or "User").strip()[:255]
                        last = (data.get("last_name") or f"Seed{i+1}").strip()[:255]
                        display_name = (data.get("display_name") or f"{first} {last}").strip()[:255]
                        experiences.extend(data.get("experiences") or [])
                    else:
                        data = await generate_more_experiences(
                            provider, first, last, background, batch_size, temperature
                        )
                        experiences.extend(data.get("experiences") or [])
                    offset += batch_size
                    if offset < num_cards and delay_sec > 0:
                        await asyncio.sleep(delay_sec)
            except ChatRateLimitError as e:
                logger.warning("User %s/%s: Rate limited (429). Try --delay 5 or higher. %s", i + 1, num_users, e)
                continue
            except ChatServiceError as e:
                logger.warning("User %s/%s: LLM error: %s", i + 1, num_users, e)
                continue
            except (json.JSONDecodeError, KeyError) as e:
                logger.warning("User %s/%s: Parse error: %s", i + 1, num_users, e)
                continue

            if not experiences:
                logger.warning("User %s/%s: No experiences returned, skipping", i + 1, num_users)
                continue

            # Skip if this seed user already exists (e.g. from a previous run)
            existing = await session.execute(select(Person).where(Person.email == email))
            if existing.scalar_one_or_none():
                logger.info("Skipping user %s/%s: %s (already exists)", i + 1, num_users, email)
                continue

            person = Person(
                email=email,
                hashed_password=hashed,
                display_name=display_name,
            )
            session.add(person)
            await session.flush()

            session.add(VisibilitySettings(person_id=person.id))
            session.add(ContactDetails(person_id=person.id))
            wallet = CreditWallet(person_id=person.id, balance=SIGNUP_CREDITS)
            session.add(wallet)
            await session.flush()
            session.add(
                CreditLedger(
                    person_id=person.id,
                    amount=SIGNUP_CREDITS,
                    reason="signup",
                    balance_after=SIGNUP_CREDITS,
                )
            )
            session.add(
                Bio(
                    person_id=person.id,
                    first_name=first,
                    last_name=last,
                )
            )

            for ex in experiences:
                if not isinstance(ex, dict):
                    continue
                raw_text = ex.get("raw_text") or ""
                start_d = _parse_date(ex.get("start_date"))
                end_d = _parse_date(ex.get("end_date"))
                child_list = ex.get("children") or []
                # Ensure unique child_type per parent (constraint)
                seen_child_types = set()
                children_dedup = []
                for c in child_list:
                    if not isinstance(c, dict):
                        continue
                    ct = (c.get("child_type") or "").strip().lower().replace("-", "_")
                    if ct not in ALLOWED_CHILD_TYPES:
                        continue
                    if ct in seen_child_types:
                        continue
                    seen_child_types.add(ct)
                    children_dedup.append(c)

                parent_card = ExperienceCard(
                    person_id=person.id,
                    title=(ex.get("title") or "")[:500] or None,
                    normalized_role=(ex.get("normalized_role") or "")[:500] or None,
                    domain=(ex.get("domain") or "")[:500] or None,
                    sub_domain=(ex.get("sub_domain") or "")[:500] or None,
                    company_name=(ex.get("company_name") or "")[:500] or None,
                    company_type=(ex.get("company_type") or "")[:255] or None,
                    start_date=start_d,
                    end_date=end_d,
                    is_current=bool(ex.get("is_current")),
                    location=(ex.get("location") or "")[:500] or None,
                    employment_type=(ex.get("employment_type") or "")[:100] or None,
                    summary=(ex.get("summary") or "")[:2000] or None,
                    raw_text=raw_text[:50000] or None,
                    intent_primary=(ex.get("intent_primary") or "")[:100] or None,
                    seniority_level=(ex.get("seniority_level") or "")[:100] or None,
                    confidence_score=0.9,
                    visibility=True,
                    search_phrases=[
                        x for x in (
                            ex.get("normalized_role"),
                            ex.get("company_name"),
                            ex.get("domain"),
                        )
                        if x
                    ],
                    search_document=(ex.get("summary") or "")[:5000] or None,
                )
                session.add(parent_card)
                await session.flush()

                for ch in children_dedup:
                    ct = (ch.get("child_type") or "").strip().lower().replace("-", "_")
                    if ct not in ALLOWED_CHILD_TYPES:
                        continue
                    label = (ch.get("label") or ct)[:255]
                    value = normalize_child_value(ch.get("value"))
                    session.add(
                        ExperienceCardChild(
                            parent_experience_id=parent_card.id,
                            person_id=person.id,
                            child_type=ct,
                            label=label,
                            value=value,
                            confidence_score=0.85,
                            search_phrases=[label, ct],
                            search_document=str(value)[:2000],
                        )
                    )

            await session.commit()
            logger.info("Seeded user %s/%s: %s (%s experiences, %s child cards)",
                        i + 1, num_users, email, len(experiences),
                        sum(len(ex.get("children") or []) for ex in experiences))

            if delay_sec > 0 and i < num_users - 1:
                logger.debug("Waiting %.1fs before next user", delay_sec)
                await asyncio.sleep(delay_sec)

    logger.info("Done. Created users with LLM-generated experiences.")
    logger.info("Password for all seed users: %s", SEED_PASSWORD)
    logger.info("Example logins: seed.llm.user1.tech@example.com, seed.llm.user2.non_tech@example.com")


def main():
    parser = argparse.ArgumentParser(description="Seed DB with LLM-generated unique users and experiences.")
    parser.add_argument("--users", type=int, default=DEFAULT_USERS, help=f"Number of users (default {DEFAULT_USERS})")
    parser.add_argument("--cards-min", type=int, default=DEFAULT_CARDS_MIN, help=f"Min experience cards per user (default {DEFAULT_CARDS_MIN})")
    parser.add_argument("--cards-max", type=int, default=DEFAULT_CARDS_MAX, help=f"Max experience cards per user (default {DEFAULT_CARDS_MAX})")
    parser.add_argument("--delay", type=float, default=DEFAULT_DELAY_SEC, help=f"Seconds between LLM calls (default {DEFAULT_DELAY_SEC})")
    parser.add_argument("--temperature", type=float, default=0.85, help="LLM temperature for creativity (default 0.85)")
    parser.add_argument("--log-level", default="INFO", choices=("DEBUG", "INFO", "WARNING", "ERROR"),
                        help="Logging level (default INFO)")
    args = parser.parse_args()
    if args.users < 1:
        args.users = 1
    if args.cards_max < args.cards_min:
        args.cards_max = args.cards_min

    logging.basicConfig(
        level=getattr(logging, args.log_level.upper()),
        format="%(asctime)s [%(levelname)s] %(message)s",
        datefmt="%H:%M:%S",
    )
    # Reduce noise from HTTP clients (httpx, httpcore, openai)
    for name in ("httpx", "httpcore", "openai"):
        logging.getLogger(name).setLevel(logging.WARNING)

    logger.info("Starting LLM seed: users=%s, cards=%s-%s, delay=%ss, temperature=%s",
                args.users, args.cards_min, args.cards_max, args.delay, args.temperature)

    try:
        asyncio.run(
            seed_with_llm(
                args.users,
                args.cards_min,
                args.cards_max,
                args.delay,
                args.temperature,
            )
        )
    except KeyboardInterrupt:
        logger.info("Interrupted by user (Ctrl+C). Exiting.")
        sys.exit(0)
    except RuntimeError as e:
        if "not configured" in str(e).lower() or "chat" in str(e).lower():
            logger.error("LLM not configured. Set OPENAI_API_KEY or CHAT_API_BASE_URL (and optionally CHAT_MODEL) in apps/api/.env")
            sys.exit(1)
        raise


if __name__ == "__main__":
    main()
